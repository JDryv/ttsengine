{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torchaudio\n",
    "from TTS.tts.configs.xtts_config import XttsConfig\n",
    "from TTS.tts.models.xtts import Xtts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XttsConfig(output_path='output', logger_uri=None, run_name='run', project_name=None, run_description='üê∏Coqui trainer run.', print_step=25, plot_step=100, model_param_stats=False, wandb_entity=None, dashboard_logger='tensorboard', save_on_interrupt=True, log_model_step=None, save_step=10000, save_n_checkpoints=5, save_checkpoints=True, save_all_best=False, save_best_after=0, target_loss=None, print_eval=False, test_delay_epochs=0, run_eval=True, run_eval_steps=None, distributed_backend='nccl', distributed_url='tcp://localhost:54321', mixed_precision=False, precision='fp16', epochs=1000, batch_size=32, eval_batch_size=16, grad_clip=0.0, scheduler_after_epoch=True, lr=0.001, optimizer='radam', optimizer_params=None, lr_scheduler=None, lr_scheduler_params={}, use_grad_scaler=False, allow_tf32=False, cudnn_enable=True, cudnn_deterministic=False, cudnn_benchmark=False, training_seed=54321, model='xtts', num_loader_workers=0, num_eval_loader_workers=0, use_noise_augment=False, audio=XttsAudioConfig(sample_rate=22050, output_sample_rate=24000), use_phonemes=False, phonemizer=None, phoneme_language=None, compute_input_seq_cache=False, text_cleaner=None, enable_eos_bos_chars=False, test_sentences_file='', phoneme_cache_path=None, characters=None, add_blank=False, batch_group_size=0, loss_masking=None, min_audio_len=1, max_audio_len=inf, min_text_len=1, max_text_len=inf, compute_f0=False, compute_energy=False, compute_linear_spec=False, precompute_num_workers=0, start_by_longest=False, shuffle=False, drop_last=False, datasets=[BaseDatasetConfig(formatter='', dataset_name='', path='', meta_file_train='', ignored_speakers=None, language='', phonemizer='', meta_file_val='', meta_file_attn_mask='')], test_sentences=[], eval_split_max_size=None, eval_split_size=0.01, use_speaker_weighted_sampler=False, speaker_weighted_sampler_alpha=1.0, use_language_weighted_sampler=False, language_weighted_sampler_alpha=1.0, use_length_weighted_sampler=False, length_weighted_sampler_alpha=1.0, model_args=XttsArgs(gpt_batch_size=1, enable_redaction=False, kv_cache=True, gpt_checkpoint=None, clvp_checkpoint=None, decoder_checkpoint=None, num_chars=255, tokenizer_file='', gpt_max_audio_tokens=605, gpt_max_text_tokens=402, gpt_max_prompt_tokens=70, gpt_layers=30, gpt_n_model_channels=1024, gpt_n_heads=16, gpt_number_text_tokens=None, gpt_start_text_token=None, gpt_stop_text_token=None, gpt_num_audio_tokens=8194, gpt_start_audio_token=8192, gpt_stop_audio_token=8193, gpt_code_stride_len=1024, gpt_use_masking_gt_prompt_approach=True, gpt_use_perceiver_resampler=False, input_sample_rate=22050, output_sample_rate=24000, output_hop_length=256, decoder_input_dim=1024, d_vector_dim=512, cond_d_vector_in_each_upsampling_layer=True, duration_const=102400), model_dir=None, languages=['en', 'es', 'fr', 'de', 'it', 'pt', 'pl', 'tr', 'ru', 'nl', 'cs', 'ar', 'zh-cn', 'hu', 'ko', 'ja', 'hi'], temperature=0.85, length_penalty=1.0, repetition_penalty=2.0, top_k=50, top_p=0.85, num_gpt_outputs=1, gpt_cond_len=12, gpt_cond_chunk_len=4, max_ref_len=10, sound_norm_refs=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loading model...\")\n",
    "config = XttsConfig()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config.load_json(\"config.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Xtts(\n",
       "  (gpt): GPT(\n",
       "    (conditioning_encoder): ConditioningEncoder(\n",
       "      (init): Conv1d(80, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (attn): Sequential(\n",
       "        (0): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (x_proj): Identity()\n",
       "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (1): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (x_proj): Identity()\n",
       "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (2): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (x_proj): Identity()\n",
       "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (3): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (x_proj): Identity()\n",
       "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (4): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (x_proj): Identity()\n",
       "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (5): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (x_proj): Identity()\n",
       "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conditioning_dropout): Dropout1d(p=0.1, inplace=False)\n",
       "    (text_embedding): Embedding(6681, 1024)\n",
       "    (mel_embedding): Embedding(1026, 1024)\n",
       "    (gpt): GPT2Model(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-29): 30 x GPT2Block(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2SdpaAttention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (mel_pos_embedding): LearnedPositionEmbeddings(\n",
       "      (emb): Embedding(608, 1024)\n",
       "    )\n",
       "    (text_pos_embedding): LearnedPositionEmbeddings(\n",
       "      (emb): Embedding(404, 1024)\n",
       "    )\n",
       "    (final_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (text_head): Linear(in_features=1024, out_features=6681, bias=True)\n",
       "    (mel_head): Linear(in_features=1024, out_features=1026, bias=True)\n",
       "    (conditioning_perceiver): PerceiverResampler(\n",
       "      (proj_context): Identity()\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x ModuleList(\n",
       "          (0): Attention(\n",
       "            (attend): Attend(\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (to_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=5460, bias=True)\n",
       "            (1): GEGLU()\n",
       "            (2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (hifigan_decoder): HifiDecoder(\n",
       "    (waveform_decoder): HifiganGenerator(\n",
       "      (conv_pre): Conv1d(1024, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      (ups): ModuleList(\n",
       "        (0): ParametrizedConvTranspose1d(\n",
       "          512, 256, kernel_size=(16,), stride=(8,), padding=(4,)\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ParametrizedConvTranspose1d(\n",
       "          256, 128, kernel_size=(16,), stride=(8,), padding=(4,)\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ParametrizedConvTranspose1d(\n",
       "          128, 64, kernel_size=(4,), stride=(2,), padding=(1,)\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ParametrizedConvTranspose1d(\n",
       "          64, 32, kernel_size=(4,), stride=(2,), padding=(1,)\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resblocks): ModuleList(\n",
       "        (0): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (8): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (conv_post): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
       "      (cond_layer): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conds): ModuleList(\n",
       "        (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(512, 64, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(512, 32, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (speaker_encoder): ResNetSpeakerEncoder(\n",
       "      (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (layer1): Sequential(\n",
       "        (0): SEBasicBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=32, out_features=4, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=4, out_features=32, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): SEBasicBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=32, out_features=4, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=4, out_features=32, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): SEBasicBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=32, out_features=4, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=4, out_features=32, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): SEBasicBlock(\n",
       "          (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): SEBasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): SEBasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): SEBasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): SEBasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): SEBasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): SEBasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): SEBasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): SEBasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): SEBasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): SEBasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=32, out_features=256, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): SEBasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=32, out_features=256, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): SEBasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=32, out_features=256, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (instancenorm): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (torch_spec): Sequential(\n",
       "        (0): PreEmphasis()\n",
       "        (1): MelSpectrogram(\n",
       "          (spectrogram): Spectrogram()\n",
       "          (mel_scale): MelScale()\n",
       "        )\n",
       "      )\n",
       "      (attention): Sequential(\n",
       "        (0): Conv1d(2048, 128, kernel_size=(1,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): Conv1d(128, 2048, kernel_size=(1,), stride=(1,))\n",
       "        (4): Softmax(dim=2)\n",
       "      )\n",
       "      (fc): Linear(in_features=4096, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Xtts.init_from_config(config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_checkpoint(config, checkpoint_dir=\"/home/jack/.local/share/tts/tts_models--multilingual--multi-dataset--xtts_v2\", use_deepspeed=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Xtts(\n",
       "  (gpt): GPT(\n",
       "    (conditioning_encoder): ConditioningEncoder(\n",
       "      (init): Conv1d(80, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (attn): Sequential(\n",
       "        (0): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (x_proj): Identity()\n",
       "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (1): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (x_proj): Identity()\n",
       "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (2): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (x_proj): Identity()\n",
       "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (3): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (x_proj): Identity()\n",
       "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (4): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (x_proj): Identity()\n",
       "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (5): AttentionBlock(\n",
       "          (norm): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
       "          (qkv): Conv1d(1024, 3072, kernel_size=(1,), stride=(1,))\n",
       "          (attention): QKVAttention()\n",
       "          (x_proj): Identity()\n",
       "          (proj_out): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conditioning_dropout): Dropout1d(p=0.1, inplace=False)\n",
       "    (text_embedding): Embedding(6681, 1024)\n",
       "    (mel_embedding): Embedding(1026, 1024)\n",
       "    (gpt): GPT2Model(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-29): 30 x GPT2Block(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2SdpaAttention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (wte): Embedding(1026, 1024)\n",
       "    )\n",
       "    (mel_pos_embedding): LearnedPositionEmbeddings(\n",
       "      (emb): Embedding(608, 1024)\n",
       "    )\n",
       "    (text_pos_embedding): LearnedPositionEmbeddings(\n",
       "      (emb): Embedding(404, 1024)\n",
       "    )\n",
       "    (final_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (text_head): Linear(in_features=1024, out_features=6681, bias=True)\n",
       "    (mel_head): Linear(in_features=1024, out_features=1026, bias=True)\n",
       "    (conditioning_perceiver): PerceiverResampler(\n",
       "      (proj_context): Identity()\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x ModuleList(\n",
       "          (0): Attention(\n",
       "            (attend): Attend(\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "            (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (to_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Linear(in_features=1024, out_features=5460, bias=True)\n",
       "            (1): GEGLU()\n",
       "            (2): Linear(in_features=2730, out_features=1024, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm): RMSNorm()\n",
       "    )\n",
       "    (gpt_inference): GPT2InferenceModel(\n",
       "      (transformer): GPT2Model(\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-29): 30 x GPT2Block(\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): GPT2SdpaAttention(\n",
       "              (c_attn): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): GPT2MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (act): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (wte): Embedding(1026, 1024)\n",
       "      )\n",
       "      (pos_embedding): LearnedPositionEmbeddings(\n",
       "        (emb): Embedding(608, 1024)\n",
       "      )\n",
       "      (embeddings): Embedding(1026, 1024)\n",
       "      (final_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (lm_head): Sequential(\n",
       "        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): Linear(in_features=1024, out_features=1026, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (hifigan_decoder): HifiDecoder(\n",
       "    (waveform_decoder): HifiganGenerator(\n",
       "      (conv_pre): Conv1d(1024, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      (ups): ModuleList(\n",
       "        (0): ParametrizedConvTranspose1d(\n",
       "          512, 256, kernel_size=(16,), stride=(8,), padding=(4,)\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ParametrizedConvTranspose1d(\n",
       "          256, 128, kernel_size=(16,), stride=(8,), padding=(4,)\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ParametrizedConvTranspose1d(\n",
       "          128, 64, kernel_size=(4,), stride=(2,), padding=(1,)\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ParametrizedConvTranspose1d(\n",
       "          64, 32, kernel_size=(4,), stride=(2,), padding=(1,)\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resblocks): ModuleList(\n",
       "        (0): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              256, 256, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              128, 128, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (8): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              64, 64, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x ParametrizedConv1d(\n",
       "              32, 32, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (parametrizations): ModuleDict(\n",
       "                (weight): ParametrizationList(\n",
       "                  (0): _WeightNorm()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (conv_post): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
       "      (cond_layer): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      (conds): ModuleList(\n",
       "        (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(512, 64, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(512, 32, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (speaker_encoder): ResNetSpeakerEncoder(\n",
       "      (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (layer1): Sequential(\n",
       "        (0): SEBasicBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=32, out_features=4, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=4, out_features=32, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): SEBasicBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=32, out_features=4, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=4, out_features=32, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): SEBasicBlock(\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=32, out_features=4, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=4, out_features=32, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): SEBasicBlock(\n",
       "          (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): SEBasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): SEBasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): SEBasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=64, out_features=8, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=8, out_features=64, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): SEBasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): SEBasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): SEBasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): SEBasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): SEBasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): SEBasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=16, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=16, out_features=128, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): SEBasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=32, out_features=256, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): SEBasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=32, out_features=256, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): SEBasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (se): SELayer(\n",
       "            (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc): Sequential(\n",
       "              (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=32, out_features=256, bias=True)\n",
       "              (3): Sigmoid()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (instancenorm): InstanceNorm1d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (torch_spec): Sequential(\n",
       "        (0): PreEmphasis()\n",
       "        (1): MelSpectrogram(\n",
       "          (spectrogram): Spectrogram()\n",
       "          (mel_scale): MelScale()\n",
       "        )\n",
       "      )\n",
       "      (attention): Sequential(\n",
       "        (0): Conv1d(2048, 128, kernel_size=(1,), stride=(1,))\n",
       "        (1): ReLU()\n",
       "        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): Conv1d(128, 2048, kernel_size=(1,), stride=(1,))\n",
       "        (4): Softmax(dim=2)\n",
       "      )\n",
       "      (fc): Linear(in_features=4096, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing speaker latents...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.4033,  0.1694,  1.1336,  ...,  0.3980, -0.6568,  0.3760],\n",
       "          [ 0.2801, -0.8360,  1.5940,  ...,  0.7739, -0.5652, -0.0047],\n",
       "          [-0.1769,  0.1562, -0.6511,  ...,  0.4006, -1.3897, -0.1062],\n",
       "          ...,\n",
       "          [ 0.2139,  0.0228, -0.1127,  ...,  0.5733, -0.2708, -0.1911],\n",
       "          [-0.4854,  1.0494,  1.1974,  ..., -0.7586, -0.2296,  0.1447],\n",
       "          [ 0.2372, -0.0682,  1.5510,  ...,  0.9232, -1.2930,  0.1247]]],\n",
       "        device='cuda:0'),\n",
       " tensor([[[-2.6305e-02],\n",
       "          [-2.7087e-02],\n",
       "          [ 2.1665e-02],\n",
       "          [-5.4963e-02],\n",
       "          [ 5.8202e-02],\n",
       "          [-4.9175e-02],\n",
       "          [-1.6467e-02],\n",
       "          [-3.8831e-02],\n",
       "          [ 4.5130e-02],\n",
       "          [-2.0003e-02],\n",
       "          [ 3.3590e-02],\n",
       "          [ 1.2272e-02],\n",
       "          [ 4.2224e-02],\n",
       "          [-2.6710e-02],\n",
       "          [-2.0062e-02],\n",
       "          [-2.1825e-03],\n",
       "          [-1.1786e-01],\n",
       "          [-6.5712e-03],\n",
       "          [-1.6502e-02],\n",
       "          [ 1.5121e-02],\n",
       "          [-1.1136e-02],\n",
       "          [-4.2897e-02],\n",
       "          [-2.7701e-02],\n",
       "          [-1.6205e-03],\n",
       "          [ 7.0620e-02],\n",
       "          [ 2.7237e-02],\n",
       "          [ 3.8320e-03],\n",
       "          [-1.1284e-02],\n",
       "          [-6.2327e-02],\n",
       "          [-4.5932e-02],\n",
       "          [ 3.9477e-02],\n",
       "          [ 7.2073e-03],\n",
       "          [-1.1352e-02],\n",
       "          [-2.0207e-02],\n",
       "          [ 1.5904e-02],\n",
       "          [ 3.9621e-02],\n",
       "          [-8.0557e-02],\n",
       "          [-1.4965e-02],\n",
       "          [-1.3468e-02],\n",
       "          [ 8.1024e-03],\n",
       "          [ 7.8118e-03],\n",
       "          [ 7.8797e-02],\n",
       "          [-1.2544e-01],\n",
       "          [ 8.5492e-03],\n",
       "          [ 1.5125e-02],\n",
       "          [-1.1878e-02],\n",
       "          [-7.6447e-03],\n",
       "          [-2.1818e-02],\n",
       "          [ 9.4465e-03],\n",
       "          [-2.8467e-03],\n",
       "          [ 1.0438e-02],\n",
       "          [-1.3558e-02],\n",
       "          [-1.8553e-02],\n",
       "          [-7.7021e-03],\n",
       "          [-5.0444e-02],\n",
       "          [-5.3845e-03],\n",
       "          [-4.6145e-02],\n",
       "          [-2.3204e-02],\n",
       "          [-1.0074e-02],\n",
       "          [ 2.5189e-02],\n",
       "          [-2.9838e-02],\n",
       "          [ 1.6018e-02],\n",
       "          [-2.1987e-01],\n",
       "          [-1.6355e-01],\n",
       "          [ 4.1340e-03],\n",
       "          [ 6.4017e-02],\n",
       "          [ 4.4001e-03],\n",
       "          [-3.7974e-03],\n",
       "          [-4.7820e-03],\n",
       "          [ 4.8434e-02],\n",
       "          [-7.6483e-03],\n",
       "          [-3.7691e-02],\n",
       "          [-3.7284e-02],\n",
       "          [ 3.3235e-02],\n",
       "          [ 9.9444e-03],\n",
       "          [ 6.5846e-03],\n",
       "          [-3.0576e-02],\n",
       "          [-3.8635e-02],\n",
       "          [-1.7390e-02],\n",
       "          [ 7.1505e-02],\n",
       "          [-1.1689e-02],\n",
       "          [-1.4527e-02],\n",
       "          [-4.6328e-04],\n",
       "          [-1.4822e-02],\n",
       "          [ 1.2127e-02],\n",
       "          [ 6.9491e-03],\n",
       "          [-8.8551e-03],\n",
       "          [-5.1610e-02],\n",
       "          [ 3.9916e-02],\n",
       "          [ 5.5451e-02],\n",
       "          [-2.7536e-02],\n",
       "          [-3.1654e-03],\n",
       "          [-5.6089e-02],\n",
       "          [-3.5404e-02],\n",
       "          [ 5.8081e-03],\n",
       "          [ 2.0996e-02],\n",
       "          [-4.3248e-02],\n",
       "          [ 5.9138e-02],\n",
       "          [-5.6678e-02],\n",
       "          [-7.7694e-02],\n",
       "          [ 1.6700e-02],\n",
       "          [ 6.6048e-03],\n",
       "          [ 2.8683e-02],\n",
       "          [-4.7766e-02],\n",
       "          [ 2.9625e-02],\n",
       "          [-2.1766e-03],\n",
       "          [ 3.3014e-02],\n",
       "          [ 3.5375e-02],\n",
       "          [-1.9684e-03],\n",
       "          [-1.7281e-02],\n",
       "          [ 1.2184e-02],\n",
       "          [ 1.0716e-02],\n",
       "          [ 5.9634e-02],\n",
       "          [-2.6610e-02],\n",
       "          [-6.8409e-03],\n",
       "          [-2.2017e-02],\n",
       "          [ 3.0248e-02],\n",
       "          [-4.2137e-02],\n",
       "          [ 1.7839e-02],\n",
       "          [ 3.9854e-02],\n",
       "          [-1.2475e-01],\n",
       "          [ 5.4274e-02],\n",
       "          [-3.9406e-03],\n",
       "          [-9.6248e-02],\n",
       "          [-2.3250e-03],\n",
       "          [ 3.3197e-02],\n",
       "          [ 2.9863e-03],\n",
       "          [ 1.5452e-02],\n",
       "          [-3.3946e-02],\n",
       "          [-2.2179e-02],\n",
       "          [-5.7356e-03],\n",
       "          [ 5.0496e-02],\n",
       "          [ 4.9221e-02],\n",
       "          [-2.0905e-02],\n",
       "          [ 7.2095e-02],\n",
       "          [ 8.1060e-02],\n",
       "          [-2.7766e-02],\n",
       "          [ 3.5800e-02],\n",
       "          [-2.2536e-03],\n",
       "          [ 1.0789e-02],\n",
       "          [-3.6585e-02],\n",
       "          [-3.0289e-03],\n",
       "          [ 2.9403e-02],\n",
       "          [-4.8186e-02],\n",
       "          [ 2.0562e-02],\n",
       "          [ 1.8209e-02],\n",
       "          [ 3.3912e-02],\n",
       "          [ 4.7525e-03],\n",
       "          [ 1.1149e-02],\n",
       "          [ 4.9119e-03],\n",
       "          [ 3.0303e-02],\n",
       "          [-4.7719e-02],\n",
       "          [-3.3014e-02],\n",
       "          [-4.5105e-02],\n",
       "          [-2.0934e-02],\n",
       "          [-1.7845e-02],\n",
       "          [ 3.3682e-02],\n",
       "          [ 1.1837e-01],\n",
       "          [-1.1334e-02],\n",
       "          [ 4.1636e-02],\n",
       "          [ 8.7895e-02],\n",
       "          [ 3.5853e-02],\n",
       "          [-2.1705e-03],\n",
       "          [-4.9754e-02],\n",
       "          [-2.2084e-02],\n",
       "          [-3.5960e-02],\n",
       "          [ 8.5368e-02],\n",
       "          [ 2.6439e-02],\n",
       "          [-2.6981e-02],\n",
       "          [-3.3183e-02],\n",
       "          [-1.7451e-02],\n",
       "          [-6.2711e-02],\n",
       "          [-1.1603e-02],\n",
       "          [-1.4488e-02],\n",
       "          [ 1.9207e-02],\n",
       "          [ 6.5589e-02],\n",
       "          [-5.6726e-02],\n",
       "          [ 5.7433e-02],\n",
       "          [ 1.9986e-02],\n",
       "          [ 5.0049e-02],\n",
       "          [-5.7829e-03],\n",
       "          [-7.0968e-03],\n",
       "          [ 5.2001e-02],\n",
       "          [ 7.2670e-04],\n",
       "          [-2.1020e-02],\n",
       "          [ 1.7766e-02],\n",
       "          [ 1.5613e-02],\n",
       "          [-1.5092e-01],\n",
       "          [ 7.9021e-03],\n",
       "          [-2.5194e-03],\n",
       "          [-2.3624e-02],\n",
       "          [-4.1848e-02],\n",
       "          [-2.6296e-03],\n",
       "          [ 4.2561e-02],\n",
       "          [ 5.0898e-02],\n",
       "          [ 8.1223e-03],\n",
       "          [-6.2434e-03],\n",
       "          [-7.3141e-02],\n",
       "          [ 2.8144e-02],\n",
       "          [-1.3767e-02],\n",
       "          [-6.4096e-03],\n",
       "          [ 2.5555e-02],\n",
       "          [ 3.3997e-02],\n",
       "          [-8.2596e-02],\n",
       "          [-1.1603e-02],\n",
       "          [-1.6202e-02],\n",
       "          [-1.3126e-03],\n",
       "          [-2.8167e-02],\n",
       "          [ 1.1327e-02],\n",
       "          [-3.6848e-02],\n",
       "          [-2.2850e-02],\n",
       "          [ 2.2315e-02],\n",
       "          [-1.6416e-01],\n",
       "          [-3.3377e-02],\n",
       "          [ 3.6400e-03],\n",
       "          [ 1.3744e-02],\n",
       "          [-4.5062e-02],\n",
       "          [ 6.5549e-03],\n",
       "          [ 7.5929e-04],\n",
       "          [ 2.4641e-01],\n",
       "          [-4.2859e-02],\n",
       "          [-2.5255e-02],\n",
       "          [-3.7580e-02],\n",
       "          [ 2.8440e-02],\n",
       "          [ 5.1139e-02],\n",
       "          [-3.2202e-02],\n",
       "          [ 2.0835e-02],\n",
       "          [ 9.1431e-03],\n",
       "          [-8.4964e-03],\n",
       "          [ 5.3175e-02],\n",
       "          [-6.1704e-02],\n",
       "          [-1.1350e-02],\n",
       "          [ 4.0979e-02],\n",
       "          [ 3.6858e-03],\n",
       "          [ 4.0147e-02],\n",
       "          [-1.3537e-02],\n",
       "          [-7.1252e-02],\n",
       "          [-9.8311e-03],\n",
       "          [-4.4816e-03],\n",
       "          [ 1.5641e-02],\n",
       "          [ 1.5051e-02],\n",
       "          [-2.9638e-02],\n",
       "          [ 4.7845e-03],\n",
       "          [ 3.4373e-03],\n",
       "          [ 6.2368e-02],\n",
       "          [ 3.6208e-02],\n",
       "          [ 1.1774e-02],\n",
       "          [ 1.5945e-02],\n",
       "          [-3.0993e-02],\n",
       "          [-2.3070e-02],\n",
       "          [-8.5317e-03],\n",
       "          [-8.6424e-04],\n",
       "          [-1.1075e-02],\n",
       "          [-3.8158e-02],\n",
       "          [-1.6213e-02],\n",
       "          [-1.5885e-02],\n",
       "          [-8.2763e-03],\n",
       "          [-4.2700e-02],\n",
       "          [ 8.7550e-03],\n",
       "          [-2.6631e-02],\n",
       "          [ 9.7055e-02],\n",
       "          [ 2.2999e-02],\n",
       "          [ 3.1636e-02],\n",
       "          [-5.7530e-02],\n",
       "          [-3.5258e-02],\n",
       "          [-1.9226e-03],\n",
       "          [-7.4986e-03],\n",
       "          [-5.0197e-03],\n",
       "          [ 2.1091e-02],\n",
       "          [-1.0177e-01],\n",
       "          [ 6.3127e-02],\n",
       "          [ 2.7281e-02],\n",
       "          [-5.6175e-02],\n",
       "          [-3.9980e-02],\n",
       "          [ 6.4544e-02],\n",
       "          [-8.6071e-02],\n",
       "          [ 2.0854e-02],\n",
       "          [ 6.8171e-02],\n",
       "          [ 1.6764e-02],\n",
       "          [-4.2809e-02],\n",
       "          [-4.4366e-03],\n",
       "          [-1.2797e-02],\n",
       "          [-8.7124e-02],\n",
       "          [ 1.5851e-02],\n",
       "          [-2.8417e-03],\n",
       "          [-5.8967e-03],\n",
       "          [-2.6984e-02],\n",
       "          [-7.0888e-03],\n",
       "          [-8.1266e-03],\n",
       "          [-6.2734e-02],\n",
       "          [ 1.9287e-02],\n",
       "          [-1.1044e-02],\n",
       "          [ 5.7645e-02],\n",
       "          [-5.2427e-02],\n",
       "          [ 3.0717e-02],\n",
       "          [-7.4219e-03],\n",
       "          [-5.3869e-02],\n",
       "          [ 5.8056e-03],\n",
       "          [-1.7710e-02],\n",
       "          [-3.4901e-03],\n",
       "          [ 1.5985e-01],\n",
       "          [ 3.6102e-03],\n",
       "          [-5.8561e-02],\n",
       "          [ 5.3733e-02],\n",
       "          [ 2.4239e-02],\n",
       "          [-1.1936e-02],\n",
       "          [-2.7591e-02],\n",
       "          [ 7.9939e-03],\n",
       "          [ 7.3247e-03],\n",
       "          [ 5.2399e-02],\n",
       "          [ 9.8722e-03],\n",
       "          [ 8.7464e-03],\n",
       "          [ 9.1177e-03],\n",
       "          [ 1.1262e-04],\n",
       "          [ 7.9504e-02],\n",
       "          [ 1.7204e-02],\n",
       "          [ 3.1083e-02],\n",
       "          [ 2.6101e-02],\n",
       "          [-5.5076e-02],\n",
       "          [-2.5455e-02],\n",
       "          [ 1.6183e-02],\n",
       "          [-3.8359e-02],\n",
       "          [ 1.1463e-02],\n",
       "          [-4.4590e-02],\n",
       "          [-5.9902e-03],\n",
       "          [ 5.4702e-03],\n",
       "          [-4.1826e-03],\n",
       "          [-9.9872e-03],\n",
       "          [ 9.4899e-04],\n",
       "          [ 7.2613e-03],\n",
       "          [ 6.1049e-02],\n",
       "          [-1.1968e-01],\n",
       "          [ 7.2881e-02],\n",
       "          [-2.0153e-02],\n",
       "          [ 3.8615e-02],\n",
       "          [-5.2101e-02],\n",
       "          [ 2.0238e-02],\n",
       "          [-3.6354e-02],\n",
       "          [-1.2093e-02],\n",
       "          [ 3.1160e-02],\n",
       "          [ 5.4743e-03],\n",
       "          [ 2.3521e-02],\n",
       "          [-9.1977e-02],\n",
       "          [-5.4650e-03],\n",
       "          [ 9.2310e-02],\n",
       "          [ 4.1002e-02],\n",
       "          [ 2.1032e-02],\n",
       "          [ 1.0251e-02],\n",
       "          [-9.2537e-03],\n",
       "          [-3.1475e-02],\n",
       "          [-1.4125e-02],\n",
       "          [ 6.3843e-02],\n",
       "          [ 4.1496e-02],\n",
       "          [ 3.9946e-02],\n",
       "          [-2.5313e-02],\n",
       "          [-2.1271e-02],\n",
       "          [ 2.1459e-02],\n",
       "          [ 2.9588e-02],\n",
       "          [-2.1213e-02],\n",
       "          [-2.9731e-02],\n",
       "          [ 1.7647e-02],\n",
       "          [-1.0501e-02],\n",
       "          [-9.3978e-02],\n",
       "          [-4.3289e-02],\n",
       "          [ 8.9800e-02],\n",
       "          [ 1.3674e-02],\n",
       "          [-4.9685e-02],\n",
       "          [-4.4831e-02],\n",
       "          [-2.5186e-02],\n",
       "          [ 3.0849e-02],\n",
       "          [ 8.8426e-03],\n",
       "          [ 4.1691e-02],\n",
       "          [ 2.0871e-02],\n",
       "          [-2.0183e-02],\n",
       "          [-2.0997e-02],\n",
       "          [ 7.1098e-03],\n",
       "          [ 5.2423e-03],\n",
       "          [-5.5127e-02],\n",
       "          [-5.0892e-03],\n",
       "          [ 5.8539e-02],\n",
       "          [ 2.7467e-02],\n",
       "          [ 6.4028e-03],\n",
       "          [ 1.1703e-02],\n",
       "          [-6.0234e-03],\n",
       "          [ 1.1039e-01],\n",
       "          [-6.1822e-02],\n",
       "          [ 5.1322e-03],\n",
       "          [-2.9487e-02],\n",
       "          [ 1.2605e-02],\n",
       "          [-1.8172e-02],\n",
       "          [-4.5110e-02],\n",
       "          [ 9.2094e-03],\n",
       "          [ 6.5218e-03],\n",
       "          [ 2.4016e-02],\n",
       "          [ 1.8330e-02],\n",
       "          [-2.8361e-02],\n",
       "          [-6.5181e-02],\n",
       "          [-8.6679e-03],\n",
       "          [ 9.0187e-02],\n",
       "          [ 1.1530e-01],\n",
       "          [ 1.6987e-02],\n",
       "          [-3.4081e-03],\n",
       "          [-6.1381e-02],\n",
       "          [-8.2636e-03],\n",
       "          [-2.9695e-02],\n",
       "          [-1.0097e-02],\n",
       "          [-6.5777e-02],\n",
       "          [ 4.3729e-03],\n",
       "          [-3.6963e-02],\n",
       "          [-2.3164e-02],\n",
       "          [ 2.1216e-02],\n",
       "          [-7.4441e-03],\n",
       "          [ 3.1752e-02],\n",
       "          [-6.8075e-03],\n",
       "          [ 4.6287e-02],\n",
       "          [ 3.2218e-03],\n",
       "          [ 6.1339e-03],\n",
       "          [ 3.2539e-02],\n",
       "          [ 4.1283e-02],\n",
       "          [ 3.9307e-02],\n",
       "          [-4.3915e-02],\n",
       "          [ 1.3685e-03],\n",
       "          [ 2.1859e-02],\n",
       "          [ 6.4371e-02],\n",
       "          [-2.1061e-02],\n",
       "          [ 2.3559e-02],\n",
       "          [ 3.5794e-02],\n",
       "          [ 1.4097e-02],\n",
       "          [ 3.3428e-02],\n",
       "          [ 7.0035e-02],\n",
       "          [ 2.0745e-02],\n",
       "          [-5.2808e-03],\n",
       "          [-3.9573e-02],\n",
       "          [ 1.1875e-02],\n",
       "          [ 4.9399e-02],\n",
       "          [-1.7829e-02],\n",
       "          [ 1.6150e-02],\n",
       "          [-1.5014e-02],\n",
       "          [-5.2843e-02],\n",
       "          [ 5.8413e-02],\n",
       "          [ 3.2565e-02],\n",
       "          [ 2.0057e-02],\n",
       "          [ 1.2044e-02],\n",
       "          [-6.3043e-02],\n",
       "          [ 7.8565e-02],\n",
       "          [ 5.0152e-03],\n",
       "          [-3.4638e-02],\n",
       "          [ 4.6164e-02],\n",
       "          [ 2.3158e-02],\n",
       "          [ 1.1138e-02],\n",
       "          [-1.8234e-02],\n",
       "          [ 3.4445e-03],\n",
       "          [ 3.1969e-03],\n",
       "          [ 8.0817e-02],\n",
       "          [ 5.9774e-03],\n",
       "          [ 2.2528e-02],\n",
       "          [ 5.0198e-02],\n",
       "          [-1.9994e-02],\n",
       "          [ 2.7093e-02],\n",
       "          [-2.8948e-03],\n",
       "          [ 3.5582e-03],\n",
       "          [-6.9821e-03],\n",
       "          [-4.0603e-03],\n",
       "          [ 1.3050e-02],\n",
       "          [ 9.3647e-03],\n",
       "          [ 1.5473e-01],\n",
       "          [-2.6051e-02],\n",
       "          [-1.4933e-02],\n",
       "          [-1.5336e-02],\n",
       "          [ 2.5477e-02],\n",
       "          [ 5.3962e-02],\n",
       "          [ 5.2034e-02],\n",
       "          [ 4.7309e-02],\n",
       "          [-7.7228e-03],\n",
       "          [ 9.2472e-02],\n",
       "          [ 4.7218e-03],\n",
       "          [-3.2857e-02],\n",
       "          [-1.6622e-03],\n",
       "          [-8.4647e-03],\n",
       "          [ 3.8630e-03],\n",
       "          [ 2.2856e-02],\n",
       "          [ 5.3690e-02],\n",
       "          [-2.4300e-02],\n",
       "          [ 3.2074e-02],\n",
       "          [ 2.6237e-02],\n",
       "          [-8.8574e-03],\n",
       "          [-3.9628e-02],\n",
       "          [ 1.6858e-02],\n",
       "          [-1.1790e-02],\n",
       "          [-1.9432e-01],\n",
       "          [-4.8855e-02],\n",
       "          [ 6.9682e-03],\n",
       "          [-4.0442e-02],\n",
       "          [ 3.4003e-02],\n",
       "          [ 4.4118e-02],\n",
       "          [ 5.0561e-03],\n",
       "          [-5.6539e-02],\n",
       "          [-1.8857e-02],\n",
       "          [-3.4294e-02],\n",
       "          [-5.1175e-03],\n",
       "          [ 7.1582e-02],\n",
       "          [ 1.7617e-02],\n",
       "          [-9.5812e-03],\n",
       "          [-4.4122e-03],\n",
       "          [-1.3248e-03],\n",
       "          [-3.4588e-03],\n",
       "          [-2.5242e-02],\n",
       "          [ 2.0542e-02],\n",
       "          [-1.8653e-02],\n",
       "          [-9.0612e-02],\n",
       "          [-2.0006e-02],\n",
       "          [-3.2859e-02]]], device='cuda:0'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(\"Computing speaker latents...\")\n",
    "gpt_cond_latent, speaker_embedding = model.get_conditioning_latents(audio_path=[\"latent_GSH.wav\"])\n",
    "gpt_cond_latent, speaker_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference...\n"
     ]
    }
   ],
   "source": [
    "print(\"Inference...\")\n",
    "t0 = time.time()\n",
    "chunks = model.inference_stream(\n",
    "        \"\"\"\n",
    "The revolution will not be right back after a message about a white tornado white lightning or white people,\n",
    "The revolution will not go better with Coke,\n",
    "The revolution will be no re-run brothers,\n",
    "The revolution will be live\"\"\",\n",
    "    \"en\",\n",
    "    gpt_cond_latent,\n",
    "    speaker_embedding\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Xtts.inference_stream at 0x7f79d2181460>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jack/.pyenv/versions/ttsengine/lib/python3.10/site-packages/TTS/tts/layers/xtts/stream_generator.py:138: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "isin() received an invalid combination of arguments - got (test_elements=int, elements=Tensor, ), but expected one of:\n * (Tensor elements, Tensor test_elements, *, bool assume_unique = False, bool invert = False, Tensor out = None)\n * (Number element, Tensor test_elements, *, bool assume_unique = False, bool invert = False, Tensor out = None)\n * (Tensor elements, Number test_element, *, bool assume_unique = False, bool invert = False, Tensor out = None)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m wav_chuncks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(chunks):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime to first chunck: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mt0\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/ttsengine/lib/python3.10/site-packages/torch/utils/_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/ttsengine/lib/python3.10/site-packages/TTS/tts/models/xtts.py:652\u001b[0m, in \u001b[0;36mXtts.inference_stream\u001b[0;34m(self, text, language, gpt_cond_latent, speaker_embedding, stream_chunk_size, overlap_wav_len, temperature, length_penalty, repetition_penalty, top_k, top_p, do_sample, speed, enable_text_splitting, **hf_generate_kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    645\u001b[0m     text_tokens\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgpt_max_text_tokens\n\u001b[1;32m    646\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ‚ùó XTTS can only generate text with a maximum of 400 tokens.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    648\u001b[0m fake_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpt\u001b[38;5;241m.\u001b[39mcompute_embeddings(\n\u001b[1;32m    649\u001b[0m     gpt_cond_latent\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice),\n\u001b[1;32m    650\u001b[0m     text_tokens,\n\u001b[1;32m    651\u001b[0m )\n\u001b[0;32m--> 652\u001b[0m gpt_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_generator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfake_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfake_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlength_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlength_penalty\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhf_generate_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    667\u001b[0m last_tokens \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    668\u001b[0m all_latents \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.pyenv/versions/ttsengine/lib/python3.10/site-packages/TTS/tts/layers/xtts/gpt.py:603\u001b[0m, in \u001b[0;36mGPT.get_generator\u001b[0;34m(self, fake_inputs, **hf_generate_kwargs)\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_generator\u001b[39m(\u001b[38;5;28mself\u001b[39m, fake_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhf_generate_kwargs):\n\u001b[0;32m--> 603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgpt_inference\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_stream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfake_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_audio_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop_audio_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop_audio_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_gen_mel_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfake_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_stream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhf_generate_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/ttsengine/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/ttsengine/lib/python3.10/site-packages/TTS/tts/layers/xtts/stream_generator.py:186\u001b[0m, in \u001b[0;36mNewGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, seed, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m requires_attention_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m requires_attention_mask \u001b[38;5;129;01mand\u001b[39;00m accepts_attention_mask:\n\u001b[0;32m--> 186\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_attention_mask_for_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# decoder-only models should use left-padding for generation\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder:\n",
      "File \u001b[0;32m~/.pyenv/versions/ttsengine/lib/python3.10/site-packages/transformers/generation/utils.py:499\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_attention_mask_for_generation\u001b[0;34m(self, inputs, pad_token_id, eos_token_id)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_greater_or_equal_than_2_4:\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;66;03m# mps does not support torch.isin for torch<2.4 (https://github.com/pytorch/pytorch/issues/77764)\u001b[39;00m\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    495\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt infer missing attention mask on `mps` device for torch<2.4. Please provide an `attention_mask` or upgrade to torch>=2.4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    496\u001b[0m     )\n\u001b[1;32m    498\u001b[0m is_pad_token_in_inputs \u001b[38;5;241m=\u001b[39m (pad_token_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m--> 499\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[43melements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_elements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39many()\n\u001b[1;32m    500\u001b[0m )\n\u001b[1;32m    501\u001b[0m is_pad_token_not_equal_to_eos_token_id \u001b[38;5;241m=\u001b[39m (eos_token_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m~\u001b[39m(\n\u001b[1;32m    502\u001b[0m     torch\u001b[38;5;241m.\u001b[39misin(elements\u001b[38;5;241m=\u001b[39meos_token_id, test_elements\u001b[38;5;241m=\u001b[39mpad_token_id)\u001b[38;5;241m.\u001b[39many()\n\u001b[1;32m    503\u001b[0m )\n\u001b[1;32m    504\u001b[0m can_infer_attention_mask \u001b[38;5;241m=\u001b[39m is_pad_token_in_inputs \u001b[38;5;241m*\u001b[39m is_pad_token_not_equal_to_eos_token_id\n",
      "\u001b[0;31mTypeError\u001b[0m: isin() received an invalid combination of arguments - got (test_elements=int, elements=Tensor, ), but expected one of:\n * (Tensor elements, Tensor test_elements, *, bool assume_unique = False, bool invert = False, Tensor out = None)\n * (Number element, Tensor test_elements, *, bool assume_unique = False, bool invert = False, Tensor out = None)\n * (Tensor elements, Number test_element, *, bool assume_unique = False, bool invert = False, Tensor out = None)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "wav_chuncks = []\n",
    "for i, chunk in enumerate(chunks):\n",
    "    if i == 0:\n",
    "        print(f\"Time to first chunck: {time.time() - t0}\")\n",
    "    print(f\"Received chunk {i} of audio length {chunk.shape[-1]}\")\n",
    "    wav_chuncks.append(chunk)\n",
    "wav = torch.cat(wav_chuncks, dim=0)\n",
    "torchaudio.save(\"xtts_streaming.wav\", wav.squeeze().unsqueeze(0).cpu(), 24000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttsengine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
